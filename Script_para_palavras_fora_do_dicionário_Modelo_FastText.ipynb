{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shaiane93-max/Dissertation-Project/blob/main/Script_para_palavras_fora_do_dicion%C3%A1rio_Modelo_FastText.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q416fX_0jFAB"
      },
      "outputs": [],
      "source": [
        "###Script continuação do R para inclusão das palavras que ficaram de fora do dicionário utilizando o fastText. Devido tamanho do arquivo fastText, foi preciso desenvolvimento no phyton"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "Yu1oD_PyjUV-",
        "outputId": "3d67d59b-3349-41f2-9210-a44cb933e587"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-416da8e9-f277-4736-9c20-b924f7ff2058\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-416da8e9-f277-4736-9c20-b924f7ff2058\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving frequencia_por_driver.xlsx to frequencia_por_driver (1).xlsx\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "vWxpwJokj3yf",
        "outputId": "98e63ec7-3095-4c50-cf08-bfc1b3e0bde0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-959a1b68-e58b-4658-a963-cbcea2355546\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-959a1b68-e58b-4658-a963-cbcea2355546\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving Dicionario_Drivers.xlsx to Dicionario_Drivers.xlsx\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYVOaqXBkBov",
        "outputId": "e1d1f65e-c373-4b6c-90f0-41deb290cfb4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting fasttext\n",
            "  Downloading fasttext-0.9.3.tar.gz (73 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/73.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.4/73.4 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pybind11>=2.2 (from fasttext)\n",
            "  Using cached pybind11-3.0.1-py3-none-any.whl.metadata (10.0 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from fasttext) (75.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from fasttext) (2.0.2)\n",
            "Using cached pybind11-3.0.1-py3-none-any.whl (293 kB)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.3-cp312-cp312-linux_x86_64.whl size=4498214 sha256=ce3bfefec3ad0e8fa9b593d5989cc7d7ca47b3ab5b5ded3a7abb2a79726bb24a\n",
            "  Stored in directory: /root/.cache/pip/wheels/20/27/95/a7baf1b435f1cbde017cabdf1e9688526d2b0e929255a359c6\n",
            "Successfully built fasttext\n",
            "Installing collected packages: pybind11, fasttext\n",
            "Successfully installed fasttext-0.9.3 pybind11-3.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install fasttext\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vFQzeNKDkjId"
      },
      "outputs": [],
      "source": [
        "# ============================\n",
        "# IMPORTS E CONFIGURAÇÃO\n",
        "# ============================\n",
        "import pandas as pd\n",
        "import fasttext\n",
        "from scipy.spatial.distance import cosine\n",
        "\n",
        "# ============================\n",
        "# FUNÇÕES AUXILIARES\n",
        "# ============================\n",
        "\n",
        "# Similaridade de cosseno entre dois vetores\n",
        "def similaridade(v1, v2):\n",
        "    return 1 - cosine(v1, v2)\n",
        "\n",
        "# Vetor da palavra (retorna None se não existir no modelo)\n",
        "def vetor_palavra(palavra, modelo):\n",
        "    try:\n",
        "        return modelo.get_word_vector(palavra)\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "# ============================\n",
        "# CARREGAR MODELO FASTTEXT\n",
        "# ============================\n",
        "modelo = fasttext.load_model(\"/content/drive/MyDrive/fastTest/cc.pt.300.bin\")\n",
        "print(\"✅ Modelo carregado com sucesso!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqJoAEUqsQSW",
        "outputId": "c08742ad-98b6-4077-b297-780593a13435"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fasttext\n",
        "import fasttext\n",
        "\n",
        "modelo = fasttext.load_model(\"/content/drive/MyDrive/fastTest/cc.pt.300.bin\")\n",
        "print(\"✅ Modelo carregado com sucesso!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CSpG0PktgSN",
        "outputId": "2996c27b-dcb0-4ba8-ddce-670c25c89733"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fasttext\n",
            "  Downloading fasttext-0.9.3.tar.gz (73 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/73.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.4/73.4 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pybind11>=2.2 (from fasttext)\n",
            "  Using cached pybind11-3.0.1-py3-none-any.whl.metadata (10.0 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from fasttext) (75.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from fasttext) (2.0.2)\n",
            "Using cached pybind11-3.0.1-py3-none-any.whl (293 kB)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.3-cp312-cp312-linux_x86_64.whl size=4498211 sha256=4d3097d2735a5d5522e7c7804ff74c5df927cd706cb3f7010bb3445bff297d8f\n",
            "  Stored in directory: /root/.cache/pip/wheels/20/27/95/a7baf1b435f1cbde017cabdf1e9688526d2b0e929255a359c6\n",
            "Successfully built fasttext\n",
            "Installing collected packages: pybind11, fasttext\n",
            "Successfully installed fasttext-0.9.3 pybind11-3.0.1\n",
            "✅ Modelo carregado com sucesso!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "/content/drive/MyDrive/fastTest/cc.pt.300.bin\n"
      ],
      "metadata": {
        "id": "2UtBugaLscZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import fasttext\n",
        "\n",
        "modelo = fasttext.load_model(\"/content/drive/MyDrive/fastTest/cc.pt.300.bin\")\n",
        "print(\"✅ Modelo carregado com sucesso!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQ63yWSisrw1",
        "outputId": "047b8707-e6cb-4476-f8dd-87cbc6eb7d5b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Modelo carregado com sucesso!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eAPKBl8-xO1D",
        "outputId": "bc865d8f-2ce6-4980-a2ad-5f2e97a44345"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 090f0c2c04efb154_733107_1261158_2024-12-15_03-13-25.zip\n",
            " 12A-Webster_240805_121900.pdf\n",
            " 147af5f7-1f31-49ed-944c-ab5b5c66d220.csv\n",
            " 18.full.pdf\n",
            "'1999_Varadarajan&Jayachandran_Marketing strategy An assessment of the state of the field and outlook.docx'\n",
            "'20250707 - parecer banca de projeto de dissertacao - Shaiane.gdoc'\n",
            "'20250707 - parecer banca de projeto de dissertacao - Shaiane.pdf'\n",
            " 25103333-homologa-servidor-24-01-23-pg-61.pdf\n",
            "'67c0d962014d7_Edital nº 49_2025 - Prorrogação do Edital Processo Seletivo para Contratação de Professor Substituto nas áreas de Administração, Ciências Biológicas e Educação Física.pdf'\n",
            " ACADÊMICO\n",
            "'A Influência da Motivação Parental nas Decisões de Consumo de Pais Mães Solo.gdoc'\n",
            "' A Influência da Motivação Parental nas Decisões de Consumo de Pais Mães Solo (Versão Desvinculada).gdoc'\n",
            "'AK SEMESTRAL NOVEMBRO 2019 NOITE.docx'\n",
            "'analise critica marketing.odt'\n",
            "'Análise de Hipóteses de Pesquisa Acadêmica.gdoc'\n",
            " articles.csv\n",
            " articles.xlsx\n",
            "'Artigos sugeridos para replicação '\n",
            "'Atendimento telefone.pdf'\n",
            "'Avaliando o ChatGPT como substituto de clientes na a medição do Customer perceived value (CPV) de um produto..docx'\n",
            "'Avaliando o ChatGPT como substituto de clientes na a medição do Customer perceived value (CPV) de um produto..gdoc'\n",
            "'BACK NOTE AUXI'\n",
            "'Bases - RSL.gsheet'\n",
            "'Colab Notebooks'\n",
            "'comprovante de matricula.pdf'\n",
            "'Conversa do WhatsApp com +55 51 8599-1141.gdoc'\n",
            "'Cópia de A Influência da Motivação Parental nas Decisões de Consumo de Pais Mães Solo - 2 de dezembro, 14:38.gdoc'\n",
            "'Cópia de A Influência da Motivação Parental nas Decisões de Consumo de Pais Mães Solo.gdoc'\n",
            "'Cópia de A Influência da Motivação Parental no Foco Temporal de Pais Mães Solo .docx'\n",
            "'Cópia de articles.xlsx'\n",
            "'Cópia de curriculo Shaiane.docx.gdoc'\n",
            "'Cópia de Ensaio para Paper - Adm de MKT.gdoc'\n",
            "'Cópia de Segurança - Artigo Brei.gdoc'\n",
            "'Crescent Pure Case (1).pdf'\n",
            "'Cronograma 2024_2_PPG ADM - Convênio.gdoc'\n",
            "'Cronograma 2024_2_PPG ADM - Convênio.pdf'\n",
            "'curriculo Shaiane.doc.gdoc'\n",
            "'curriculo Shaiane.docx.gdoc'\n",
            "'Desafios da orientação para o cliente - O lado obscuro da cultura organizacional e os comportamentos sabotadores - Uma perspectiva teórica e gerencial (1).pdf'\n",
            "'Desafios da orientação para o cliente - O lado obscuro da cultura organizacional e os comportamentos sabotadores - Uma perspectiva teórica e gerencial.pdf'\n",
            "'Descrição cargos (5).xlsx'\n",
            "'Descrição cargos.xlsx.gsheet'\n",
            "'Desenho Experimental (Questionário) (1).pdf'\n",
            "'Desenho Experimental (Questionário) (2).pdf'\n",
            "'Desenho Experimental (Questionário) (3).pdf'\n",
            "'Desenho Experimental (Questionário).gdoc'\n",
            "'Desenho Experimental (Questionário).pdf'\n",
            " Dicionario\n",
            "'Documento sem título (1).gdoc'\n",
            "'Documento sem título (2).gdoc'\n",
            "'Documento sem título (3).gdoc'\n",
            "'Documento sem título (4).gdoc'\n",
            "'Documento sem título.gdoc'\n",
            "'Doe 04-11-2022 pag 46-48_888 (1).pdf'\n",
            "'Doe 04-11-2022 pag 46-48_888.pdf'\n",
            "'DOE_2022-11-10 EDITAL SERVIDOR DE ESCOLA_483.pdf'\n",
            "'Encontro 7 - Estratégia de Produto (1) (1).pdf'\n",
            "'Encontro 7 - Estratégia de Produto (1).pdf'\n",
            "'Ensaios de Aula'\n",
            "'Ensaio Teórico - Thais Monteiro - PARTE 1_Cristiane.docx'\n",
            "'Escala HED UT.gsheet'\n",
            "'Escala Tensao de Papeis.gsheet'\n",
            "'Escala Voss.gsheet'\n",
            "'Estudo de Caso capítulo 11 - Gráfico de barras 1.gsheet'\n",
            "'Estudo de Caso capítulo 11 - Gráfico de colunas 1.gsheet'\n",
            "'ESTUDO DO PERFIL E COMPORTAMENTO DOS CLIENTES QUE BUSCAM IMÓVEIS PARA LOCAÇÃO EM PORTO ALEGRE.docx'\n",
            "'ESTUDO DO PERFIL E COMPORTAMENTO DOS CLIENTES QUE BUSCAM IMÓVEIS PARA LOCAÇÃO EM PORTO ALEGRE (Salvo Automaticamente).docx'\n",
            " fastTest\n",
            "'Fichamento RSL (21 a 35).gdoc'\n",
            "'Firestorms - Quando a Reputação da Marca é o Alvo nas Mídias Sociais - Versão Final.docx'\n",
            "'Formulário sem título (1).gform'\n",
            "'Formulário sem título.gform'\n",
            "'Formulário sem título (respostas).gsheet'\n",
            "'Gemini, gostaria de um material de correção para....gsheet'\n",
            " História.docx.gdoc\n",
            "'Ideias de Pesquisa (Painel interativo).pdf'\n",
            "'Imagens Qualtrics'\n",
            "'Inteligência Artificial e Arrependimento Pós-Com_241107_191938.pdf'\n",
            "' Interações Sociais e as Preferências de Consumo.gform'\n",
            "'Interações Sociais e Preferências de Consumo.gform'\n",
            "'Interações Sociais e Preferências de Consumo (respostas).gsheet'\n",
            " intro_ANOVA.xlsx\n",
            "'INTRODUÇÃO-Avaliação de desempenho.docx.gdoc'\n",
            "'Introdução Paper - Adminsitração de marketing.gdoc'\n",
            "'Introdução sobre a empresa Natura (1).docx.gdoc'\n",
            "'Introdução sobre a empresa Natura.docx.gdoc'\n",
            "'IP 12.08.gdoc'\n",
            "'IP 12.08.odt'\n",
            "'jagsheth.com-Feeling the Heat Part 2 (1).pdf'\n",
            "'Leituras Cleo'\n",
            "'Lista de convidados.ods'\n",
            "'LOGO VICKENZO - PARA PLACA.pdf'\n",
            "'MAPEAMENTO DO PROCESSO.docx.gdoc'\n",
            "'Material Exercício  Centralidade do Cliente'\n",
            "'Matriz BCG.gdoc'\n",
            "'Meet Recordings'\n",
            " MindMeister\n",
            "'Negativas de Propriedade'\n",
            "' O Peso de ser Dois em Um: A Tensão de Papéis e o Consumo Hedônico de Mães e Pais Solo.gdoc'\n",
            "'O Peso de ser Dois em Um: A Tensão de Papéis e o Consumo Hedônico de Mães e Pais Solo.gdoc'\n",
            "'O Peso de ser Dois em Um -  A Tensão de Papeis e o Consumo Hedonico de Maes e Pais Solo.pdf'\n",
            "' O Peso de ser Dois em Um: A Tensão de Papéis e o Consumo Hedônico de Mães e Pais Solo (versão final).gdoc'\n",
            "'Pesquisa Estágio II.gform'\n",
            "'Pesquisa Estágio II (respostas).gsheet'\n",
            "' Pesquisa - Experiências de Compra.gform'\n",
            "'Pesquisa - Experiências de Compra.gform'\n",
            "' Pesquisa - Experiências de Compra (respostas).gsheet'\n",
            "'Pesquisa - Experiências de Compra (respostas).gsheet'\n",
            " Pessoal\n",
            "'Plano de Ações de Marketing.xls'\n",
            "'Plano_de_Ensino_Comportamento do Consumidor 2024 ALUNO Seminarios (1).doc'\n",
            "'Plano_de_Ensino_Comportamento do Consumidor 2024 ALUNO Seminarios.doc'\n",
            "'Produtos (3).xlsx'\n",
            "'Projeções_relatório (1).xlsx.gsheet'\n",
            " Projeções_relatório.xlsx.gsheet\n",
            "'protocolo chaves 18.12 (1).gdoc'\n",
            "'protocolo chaves 18.12.gdoc'\n",
            "'Questões para Estudo dirigido consumidor.doc'\n",
            "'Questões para Estudo dirigido consumidor.doc.gdoc'\n",
            "'Questões para Estudo dirigido direito do trabalho..doc'\n",
            "'Questões para Estudo dirigido direito do trabalho..doc.gdoc'\n",
            "'Rafael Garcia Ribeiro.gdoc'\n",
            "'Rascunho  - Adm de MKT.gdoc'\n",
            "'Redes - Pacotes turísticos.xlsx'\n",
            "'Relacionamentos e as Preferências de Consumo .gform'\n",
            "'Relacionamentos e as Preferências de Consumo  (respostas).gsheet'\n",
            "'Relacionamentos e Preferências de Consumo.gform'\n",
            "'Relacionamentos e Preferências de Consumo (respostas).gsheet'\n",
            "'Roteiro - Aula 14 (Grupos de Influência).docx'\n",
            "'Roteiro - Aula 14 (Grupos de Influência).gdoc'\n",
            "'RSL - Revisão Sistemática de Literatura.gdoc'\n",
            "' RSL - Revisão Sistemática de Literatura - Versão Final - OSF.gdoc'\n",
            "'RSL - Teoria da Tensão de Papéis.gsheet'\n",
            "'Saved from Chrome'\n",
            "'Scopus (20.01.25).csv'\n",
            "'Scopus (20.01.25).gsheet'\n",
            " scopus.csv\n",
            " scopus.gsheet\n",
            "'Scopus - Serviços Concatenados.xlsx'\n",
            "'Scopus - Spillover.xlsx'\n",
            "'Screen_Recording_20240808_184527_Samsung Notes.mp4'\n",
            "'Sem título.gdoc'\n",
            "'Simulated_Interacoes_Sociais (1) - CORRIGIDA.xlsx'\n",
            "'Simulated_Relacionamentos - CORRIGIDA.xlsx'\n",
            "'Spillover - Bibliometric.xlsx'\n",
            "'Spillover - Negative.xlsx'\n",
            " TCC.gdoc\n",
            " termo.pdf\n",
            "'Teste Ancoras de Carreira Robert Half (1).xlsx'\n",
            " tga.gdoc\n",
            "'TRABALHO ESCRITO.docx.gdoc'\n",
            " trabalhofinaltga.docx.gdoc\n",
            "'trabalho final tga.gdoc'\n",
            "'TRABALHO TGA EDITADO (1).docx.gdoc'\n",
            "'TRABALHO TGA EDITADO (2).docx.gdoc'\n",
            "'TRABALHO TGA EDITADO (3).docx.gdoc'\n",
            "'TRABALHO TGA EDITADO (4).docx.gdoc'\n",
            "'TRABALHO TGA EDITADO (5).docx.gdoc'\n",
            "'TRABALHO TGA EDITADO.docx.gdoc'\n",
            " U118O6L929309.PDF\n",
            "'Universalidade de Marketing - Aula 10.pdf'\n",
            "'WORD ORDER.docx'\n",
            " Word_order_questions_do_does.docx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/Dicionario\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdAaCw7ExWR_",
        "outputId": "99e2d4aa-e7cb-43a3-a44a-51363663e035"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dicionario_Drivers.xlsx  frequencia_por_driver.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================\n",
        "# IMPORTS E CONFIGURAÇÃO\n",
        "# ============================\n",
        "import pandas as pd\n",
        "import fasttext\n",
        "from scipy.spatial.distance import cosine\n",
        "\n",
        "# ============================\n",
        "# FUNÇÕES AUXILIARES\n",
        "# ============================\n",
        "\n",
        "# Similaridade de cosseno entre dois vetores\n",
        "def similaridade(v1, v2):\n",
        "    return 1 - cosine(v1, v2)\n",
        "\n",
        "# Vetor da palavra (retorna None se não existir no modelo)\n",
        "def vetor_palavra(texto, modelo):\n",
        "    try:\n",
        "        # Faz média dos vetores das palavras dentro da frase/descrição\n",
        "        palavras = str(texto).split()\n",
        "        vetores = [modelo.get_word_vector(p) for p in palavras if p.strip() != \"\"]\n",
        "        return sum(vetores) / len(vetores)\n",
        "    except Exception as e:\n",
        "        return None\n",
        "\n",
        "# ============================\n",
        "# CARREGAR ARQUIVOS\n",
        "# ============================\n",
        "\n",
        "# Ajuste os caminhos de acordo com seu Google Drive\n",
        "dicionario = pd.read_excel(\"/content/drive/MyDrive/Dicionario/Dicionario_Drivers.xlsx\")\n",
        "palavras_nc = pd.read_excel(\"/content/drive/MyDrive/Dicionario/frequencia_por_driver.xlsx\", sheet_name=\"Palavras_Nao_Classificadas\")\n",
        "\n",
        "# ============================\n",
        "# MODELO FASTTEXT (já carregado)\n",
        "# ============================\n",
        "# Se já carregou antes, pode pular esta parte.\n",
        "# modelo = fasttext.load_model(\"/content/drive/MyDrive/fastTest/cc.pt.300.bin\")\n",
        "\n",
        "# ============================\n",
        "# NORMALIZAÇÃO (lowercase e strip)\n",
        "# ============================\n",
        "if 'descricao' in dicionario.columns:\n",
        "    dicionario['descricao_norm'] = dicionario['descricao'].fillna('').str.lower().str.strip()\n",
        "else:\n",
        "    print(\"⚠️ Coluna 'descricao' não encontrada no dicionário! Verifique o nome da coluna.\")\n",
        "\n",
        "palavras_nc['Palavra'] = palavras_nc['Palavra'].astype(str).str.lower().str.strip()\n",
        "\n",
        "# ============================\n",
        "# CALCULAR SUGESTÕES\n",
        "# ============================\n",
        "sugestoes_list = []\n",
        "\n",
        "for idx, row in palavras_nc.iterrows():\n",
        "    palavra = row['Palavra']\n",
        "    vec_pal = vetor_palavra(palavra, modelo)\n",
        "    if vec_pal is None:\n",
        "        continue\n",
        "\n",
        "    sims = []\n",
        "    for jdx, desc_row in dicionario.iterrows():\n",
        "        vec_desc = vetor_palavra(desc_row['descricao_norm'], modelo)\n",
        "        if vec_desc is None:\n",
        "            continue\n",
        "        sims.append((desc_row.get('driver', ''), desc_row.get('subdriver', ''), similaridade(vec_pal, vec_desc)))\n",
        "\n",
        "    # Ordena e pega top 3 sugestões\n",
        "    sims_sorted = sorted(sims, key=lambda x: x[2], reverse=True)[:3]\n",
        "    for s in sims_sorted:\n",
        "        sugestoes_list.append({'Palavra': palavra, 'Driver': s[0], 'Subdriver': s[1], 'Similaridade': s[2]})\n",
        "\n",
        "# Criar DataFrame final\n",
        "sugestoes_df = pd.DataFrame(sugestoes_list)\n",
        "sugestoes_df = sugestoes_df.sort_values(['Palavra', 'Similaridade'], ascending=[True, False])\n",
        "\n",
        "# ============================\n",
        "# SALVAR EM EXCEL\n",
        "# ============================\n",
        "output_path = \"/content/drive/MyDrive/Dicionario/sugestoes.xlsx\"\n",
        "with pd.ExcelWriter(output_path) as writer:\n",
        "    palavras_nc.to_excel(writer, sheet_name=\"Palavras_Nao_Classificadas\", index=False)\n",
        "    sugestoes_df.to_excel(writer, sheet_name=\"Sugestoes_De_Encaixe\", index=False)\n",
        "\n",
        "print(f\"💾 Arquivo salvo com sucesso em: {output_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fi0S4b2SwHS0",
        "outputId": "ac5cecf4-9a73-4513-9f18-c81c87178df3"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/scipy/spatial/distance.py:682: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  dist = 1.0 - uv / math.sqrt(uu * vv)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "💾 Arquivo salvo com sucesso em: /content/drive/MyDrive/Dicionario/sugestoes.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###Classificando as sugestões por similaridade####\n",
        "# ============================\n",
        "# Classificar similaridade\n",
        "# ============================\n",
        "def classifica_sim(sim):\n",
        "    if sim >= 0.7:\n",
        "        return \"Alta\"\n",
        "    elif sim >= 0.5:\n",
        "        return \"Média\"\n",
        "    else:\n",
        "        return \"Baixa\"\n",
        "\n",
        "sugestoes_df['Classificacao'] = sugestoes_df['Similaridade'].apply(classifica_sim)\n",
        "\n",
        "# ============================\n",
        "# Salvar resultados no Excel\n",
        "# ============================\n",
        "with pd.ExcelWriter(\"/content/drive/MyDrive/Dicionario/sugestoes_classificadas.xlsx\") as writer:\n",
        "    palavras_nc.to_excel(writer, sheet_name=\"Palavras_Nao_Classificadas\", index=False)\n",
        "    sugestoes_df.to_excel(writer, sheet_name=\"Sugestoes_De_Encaixe\", index=False)\n",
        "\n",
        "print(\"💾 Arquivo salvo: sugestoes_classificadas.xlsx\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6G-_rRvrzi7F",
        "outputId": "14233e81-9886-4e9d-c1a7-6bd8be64765a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "💾 Arquivo salvo: sugestoes_classificadas.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "####Tentando melhorar as sugestões de classificação de palavras pelo FastTest usando uma versão mais robusta para o FastTest:\n",
        "\n",
        "import pandas as pd\n",
        "from scipy.spatial.distance import cosine\n",
        "\n",
        "# ============================\n",
        "# FUNÇÕES AUXILIARES\n",
        "# ============================\n",
        "\n",
        "def similaridade(v1, v2):\n",
        "    return 1 - cosine(v1, v2)\n",
        "\n",
        "def vetor_palavra(palavra, modelo):\n",
        "    try:\n",
        "        return modelo.get_word_vector(palavra)\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "def ajustar_valencia(sim, palavra_val, desc_val):\n",
        "    \"\"\"\n",
        "    Ajusta a similaridade de acordo com a valência:\n",
        "    - Mesma valência -> reforça (multiplica 1.2)\n",
        "    - Valência oposta -> penaliza (multiplica 0.8)\n",
        "    - Sem valência -> mantém\n",
        "    \"\"\"\n",
        "    if pd.isna(palavra_val) or pd.isna(desc_val):\n",
        "        return sim\n",
        "    if palavra_val == desc_val:\n",
        "        return sim * 1.2\n",
        "    elif palavra_val != desc_val:\n",
        "        return sim * 0.8\n",
        "    else:\n",
        "        return sim\n",
        "\n",
        "# ============================\n",
        "# CARREGAR PLANILHAS\n",
        "# ============================\n",
        "\n",
        "palavras_nc = pd.read_excel(\"/content/drive/MyDrive/Dicionario/sugestoes_classificadas.xlsx\",\n",
        "                            sheet_name=\"Palavras_Nao_Classificadas\")\n",
        "\n",
        "dicionario = pd.read_excel(\"/content/drive/MyDrive/Dicionario/Dicionario_Drivers.xlsx\")\n",
        "\n",
        "# Adiciona coluna de valência\n",
        "dicionario['valencia'] = dicionario.apply(\n",
        "    lambda row: 'positivo' if pd.notna(row['dicionarioP']) else ('negativo' if pd.notna(row['dicionarioN']) else None),\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "# Normalização\n",
        "dicionario['descricao_norm'] = dicionario['descricao'].fillna('').str.lower().str.strip()\n",
        "palavras_nc['Palavra'] = palavras_nc['Palavra'].astype(str).str.lower().str.strip()\n",
        "\n",
        "# ============================\n",
        "# Dicionários de valência para palavras não classificadas\n",
        "# ============================\n",
        "\n",
        "# Cria um dicionário rápido para palavras do dicionário\n",
        "valencia_dict = {}\n",
        "for idx, row in dicionario.iterrows():\n",
        "    for col in ['dicionarioP', 'dicionarioN']:\n",
        "        palavra = row[col]\n",
        "        if pd.notna(palavra):\n",
        "            palavra_norm = palavra.lower().strip()\n",
        "            valencia_dict[palavra_norm] = 'positivo' if col=='dicionarioP' else 'negativo'\n",
        "\n",
        "# ============================\n",
        "# GERAÇÃO DE SUGESTÕES AVANÇADAS\n",
        "# ============================\n",
        "\n",
        "def gerar_sugestoes_avancadas(palavras_df, dicionario, top_n=3, threshold_sim=0.3):\n",
        "    sugestoes_list = []\n",
        "\n",
        "    for idx, row in palavras_df.iterrows():\n",
        "        palavra = row['Palavra']\n",
        "        freq = row.get('Frequencia', 1)  # se houver coluna de frequência\n",
        "        palavra_val = valencia_dict.get(palavra, None)\n",
        "\n",
        "        vec_pal = vetor_palavra(palavra, modelo)\n",
        "        if vec_pal is None:\n",
        "            continue\n",
        "\n",
        "        sims = []\n",
        "        for jdx, desc_row in dicionario.iterrows():\n",
        "            vec_desc = vetor_palavra(desc_row['descricao_norm'], modelo)\n",
        "            if vec_desc is None:\n",
        "                continue\n",
        "            sim = similaridade(vec_pal, vec_desc)\n",
        "            sim = ajustar_valencia(sim, palavra_val, desc_row['valencia'])\n",
        "            if sim >= threshold_sim:\n",
        "                sims.append((desc_row['driver'], desc_row['subdriver'], desc_row['valencia'], sim))\n",
        "\n",
        "        sims_sorted = sorted(sims, key=lambda x: (x[3], freq), reverse=True)[:top_n]\n",
        "\n",
        "        for s in sims_sorted:\n",
        "            sugestoes_list.append({\n",
        "                'Palavra': palavra,\n",
        "                'Frequencia': freq,\n",
        "                'Driver': s[0],\n",
        "                'Subdriver': s[1],\n",
        "                'Valencia': s[2],\n",
        "                'Similaridade': s[3]\n",
        "            })\n",
        "\n",
        "    return pd.DataFrame(sugestoes_list)\n",
        "\n",
        "# ============================\n",
        "# RODAR SUGESTÕES\n",
        "# ============================\n",
        "\n",
        "sugestoes_df = gerar_sugestoes_avancadas(palavras_nc, dicionario, top_n=3, threshold_sim=0.3)\n",
        "sugestoes_df = sugestoes_df.sort_values(['Palavra', 'Similaridade'], ascending=[True, False])\n",
        "\n",
        "# ============================\n",
        "# CLASSIFICAR POR SIMILARIDADE\n",
        "# ============================\n",
        "\n",
        "def classifica_sim(sim):\n",
        "    if sim >= 0.7:\n",
        "        return \"Alta\"\n",
        "    elif sim >= 0.5:\n",
        "        return \"Média\"\n",
        "    else:\n",
        "        return \"Baixa\"\n",
        "\n",
        "sugestoes_df['Classificacao'] = sugestoes_df['Similaridade'].apply(classifica_sim)\n",
        "\n",
        "# ============================\n",
        "# SALVAR RESULTADOS COM CLASSIFICAÇÃO\n",
        "# ============================\n",
        "\n",
        "with pd.ExcelWriter(\"/content/drive/MyDrive/Dicionario/sugestoes_classificadas.xlsx\", mode='a', if_sheet_exists='replace') as writer:\n",
        "    palavras_nc.to_excel(writer, sheet_name=\"Palavras_Nao_Classificadas\", index=False)\n",
        "    sugestoes_df.to_excel(writer, sheet_name=\"Sugestoes_FastText_Avancadas\", index=False)\n",
        "\n",
        "print(\"💾 Arquivo atualizado com aba: Sugestoes_FastText_Avancadas e Classificacao de Similaridade\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RIGOCGawAJnA",
        "outputId": "bc1049c0-7801-43bf-a92b-1bec6a384f5b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/scipy/spatial/distance.py:682: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  dist = 1.0 - uv / math.sqrt(uu * vv)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "💾 Arquivo atualizado com aba: Sugestoes_FastText_Avancadas e Classificacao de Similaridade\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#### Algumas palavras foram classificadas como positivas mas, claramente são negativas ex: denuncia. Tentando um dicionário de antônimos para ver se melhora####\n",
        "\n",
        "#### Sugestões FastText aprimoradas com detecção automática de valência e consolidação ####\n",
        "\n",
        "import pandas as pd\n",
        "from scipy.spatial.distance import cosine\n",
        "import math\n",
        "\n",
        "# ============================\n",
        "# FUNÇÕES AUXILIARES\n",
        "# ============================\n",
        "\n",
        "def similaridade(v1, v2):\n",
        "    return 1 - cosine(v1, v2)\n",
        "\n",
        "def vetor_palavra(palavra, modelo):\n",
        "    try:\n",
        "        return modelo.get_word_vector(palavra)\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "def detectar_valencia(palavra_vec, pos_vecs, neg_vecs):\n",
        "    \"\"\"\n",
        "    Detecta a valência da palavra com base na similaridade média com\n",
        "    palavras positivas e negativas do dicionário.\n",
        "    Retorna 'positivo', 'negativo' ou None.\n",
        "    \"\"\"\n",
        "    if palavra_vec is None:\n",
        "        return None\n",
        "\n",
        "    sim_pos = [similaridade(palavra_vec, v) for v in pos_vecs if v is not None]\n",
        "    sim_neg = [similaridade(palavra_vec, v) for v in neg_vecs if v is not None]\n",
        "\n",
        "    mean_pos = sum(sim_pos)/len(sim_pos) if sim_pos else 0\n",
        "    mean_neg = sum(sim_neg)/len(sim_neg) if sim_neg else 0\n",
        "\n",
        "    if mean_pos > mean_neg:\n",
        "        return 'positivo'\n",
        "    elif mean_neg > mean_pos:\n",
        "        return 'negativo'\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "# ============================\n",
        "# CARREGAR PLANILHAS\n",
        "# ============================\n",
        "\n",
        "palavras_nc = pd.read_excel(\"/content/drive/MyDrive/Dicionario/sugestoes_classificadas.xlsx\",\n",
        "                            sheet_name=\"Palavras_Nao_Classificadas\")\n",
        "\n",
        "dicionario = pd.read_excel(\"/content/drive/MyDrive/Dicionario/Dicionario_Drivers.xlsx\")\n",
        "\n",
        "# Adiciona coluna de valência\n",
        "dicionario['valencia'] = dicionario.apply(\n",
        "    lambda row: 'positivo' if pd.notna(row['dicionarioP']) else ('negativo' if pd.notna(row['dicionarioN']) else None),\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "# Normalização\n",
        "dicionario['descricao_norm'] = dicionario['descricao'].fillna('').str.lower().str.strip()\n",
        "palavras_nc['Palavra'] = palavras_nc['Palavra'].astype(str).str.lower().str.strip()\n",
        "\n",
        "# ============================\n",
        "# Criar listas de vetores positivos e negativos do dicionário\n",
        "# ============================\n",
        "\n",
        "palavras_positivas = [p.lower().strip() for p in dicionario['dicionarioP'].dropna()]\n",
        "palavras_negativas = [p.lower().strip() for p in dicionario['dicionarioN'].dropna()]\n",
        "\n",
        "pos_vecs = [vetor_palavra(p, modelo) for p in palavras_positivas]\n",
        "neg_vecs = [vetor_palavra(p, modelo) for p in palavras_negativas]\n",
        "\n",
        "# ============================\n",
        "# GERAÇÃO DE SUGESTÕES APRIMORADAS\n",
        "# ============================\n",
        "\n",
        "def gerar_sugestoes_valencia_automatica(palavras_df, dicionario, top_n=3, threshold_sim=0.3):\n",
        "    sugestoes_list = []\n",
        "\n",
        "    for idx, row in palavras_df.iterrows():\n",
        "        palavra = row['Palavra']\n",
        "        freq = row.get('Frequencia', 1)\n",
        "        vec_pal = vetor_palavra(palavra, modelo)\n",
        "        if vec_pal is None:\n",
        "            continue\n",
        "\n",
        "        palavra_val = detectar_valencia(vec_pal, pos_vecs, neg_vecs)\n",
        "\n",
        "        sims = []\n",
        "        for jdx, desc_row in dicionario.iterrows():\n",
        "            vec_desc = vetor_palavra(desc_row['descricao_norm'], modelo)\n",
        "            if vec_desc is None:\n",
        "                continue\n",
        "\n",
        "            sim = similaridade(vec_pal, vec_desc)\n",
        "\n",
        "            # Ajusta similaridade por valência\n",
        "            if palavra_val == desc_row['valencia']:\n",
        "                sim *= 1.2\n",
        "            elif palavra_val and desc_row['valencia'] and palavra_val != desc_row['valencia']:\n",
        "                sim *= 0.8\n",
        "\n",
        "            if sim >= threshold_sim:\n",
        "                sim_freq = sim * math.log(1 + freq)\n",
        "                sims.append((desc_row['driver'], desc_row['subdriver'], desc_row['valencia'], sim_freq))\n",
        "\n",
        "        sims_sorted = sorted(sims, key=lambda x: x[3], reverse=True)[:top_n]\n",
        "\n",
        "        for s in sims_sorted:\n",
        "            sugestoes_list.append({\n",
        "                'Palavra': palavra,\n",
        "                'Frequencia': freq,\n",
        "                'Driver': s[0],\n",
        "                'Subdriver': s[1],\n",
        "                'Valencia': s[2],\n",
        "                'Similaridade': s[3]\n",
        "            })\n",
        "\n",
        "    return pd.DataFrame(sugestoes_list)\n",
        "\n",
        "# ============================\n",
        "# RODAR SUGESTÕES\n",
        "# ============================\n",
        "\n",
        "sugestoes_df = gerar_sugestoes_valencia_automatica(palavras_nc, dicionario, top_n=3, threshold_sim=0.3)\n",
        "sugestoes_df = sugestoes_df.sort_values(['Palavra', 'Similaridade'], ascending=[True, False])\n",
        "\n",
        "# ============================\n",
        "# CONSOLIDAR PALAVRAS PARA TER APENAS UMA LINHA POR PALAVRA\n",
        "# ============================\n",
        "\n",
        "sugestoes_consolidadas = sugestoes_df.groupby('Palavra').agg({\n",
        "    'Frequencia': 'first',\n",
        "    'Driver': lambda x: ', '.join(x.unique()),\n",
        "    'Subdriver': lambda x: ', '.join(x.unique()),\n",
        "    'Valencia': lambda x: ', '.join(x.unique()),\n",
        "    'Similaridade': 'max'\n",
        "}).reset_index()\n",
        "\n",
        "# Classificação por similaridade\n",
        "def classifica_sim(sim):\n",
        "    if sim >= 0.7:\n",
        "        return \"Alta\"\n",
        "    elif sim >= 0.5:\n",
        "        return \"Média\"\n",
        "    else:\n",
        "        return \"Baixa\"\n",
        "\n",
        "sugestoes_consolidadas['Classificacao'] = sugestoes_consolidadas['Similaridade'].apply(classifica_sim)\n",
        "\n",
        "# ============================\n",
        "# SALVAR RESULTADOS NO EXCEL\n",
        "# ============================\n",
        "\n",
        "with pd.ExcelWriter(\"/content/drive/MyDrive/Dicionario/sugestoes_classificadas.xlsx\", mode='a', if_sheet_exists='replace') as writer:\n",
        "    palavras_nc.to_excel(writer, sheet_name=\"Palavras_Nao_Classificadas\", index=False)\n",
        "    sugestoes_consolidadas.to_excel(writer, sheet_name=\"Sugestoes_FastText_Avancadas\", index=False)\n",
        "\n",
        "print(\"💾 Arquivo atualizado com aba: Sugestoes_FastText_Avancadas e Classificacao de Similaridade\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jllTeO9TAPQ8",
        "outputId": "af6502a2-3b3d-4729-eff3-2caefd7d1721"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/scipy/spatial/distance.py:682: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  dist = 1.0 - uv / math.sqrt(uu * vv)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "💾 Arquivo atualizado com aba: Sugestoes_FastText_Avancadas e Classificacao de Similaridade\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H-EdJ0xIDuJ6"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN/NcTgJ93WfPzhE2RNMbj2",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}