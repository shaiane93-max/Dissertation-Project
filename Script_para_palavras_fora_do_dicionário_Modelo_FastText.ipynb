{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shaiane93-max/Dissertation-Project/blob/main/Script_para_palavras_fora_do_dicion%C3%A1rio_Modelo_FastText.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q416fX_0jFAB"
      },
      "outputs": [],
      "source": [
        "###Script continua√ß√£o do R para inclus√£o das palavras que ficaram de fora do dicion√°rio utilizando o fastText. Devido tamanho do arquivo fastText, foi preciso desenvolvimento no phyton"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "Yu1oD_PyjUV-",
        "outputId": "3d67d59b-3349-41f2-9210-a44cb933e587"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-416da8e9-f277-4736-9c20-b924f7ff2058\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-416da8e9-f277-4736-9c20-b924f7ff2058\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving frequencia_por_driver.xlsx to frequencia_por_driver (1).xlsx\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "vWxpwJokj3yf",
        "outputId": "98e63ec7-3095-4c50-cf08-bfc1b3e0bde0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-959a1b68-e58b-4658-a963-cbcea2355546\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-959a1b68-e58b-4658-a963-cbcea2355546\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving Dicionario_Drivers.xlsx to Dicionario_Drivers.xlsx\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYVOaqXBkBov",
        "outputId": "e1d1f65e-c373-4b6c-90f0-41deb290cfb4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting fasttext\n",
            "  Downloading fasttext-0.9.3.tar.gz (73 kB)\n",
            "\u001b[?25l     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/73.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m73.4/73.4 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pybind11>=2.2 (from fasttext)\n",
            "  Using cached pybind11-3.0.1-py3-none-any.whl.metadata (10.0 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from fasttext) (75.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from fasttext) (2.0.2)\n",
            "Using cached pybind11-3.0.1-py3-none-any.whl (293 kB)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.3-cp312-cp312-linux_x86_64.whl size=4498214 sha256=ce3bfefec3ad0e8fa9b593d5989cc7d7ca47b3ab5b5ded3a7abb2a79726bb24a\n",
            "  Stored in directory: /root/.cache/pip/wheels/20/27/95/a7baf1b435f1cbde017cabdf1e9688526d2b0e929255a359c6\n",
            "Successfully built fasttext\n",
            "Installing collected packages: pybind11, fasttext\n",
            "Successfully installed fasttext-0.9.3 pybind11-3.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install fasttext\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vFQzeNKDkjId"
      },
      "outputs": [],
      "source": [
        "# ============================\n",
        "# IMPORTS E CONFIGURA√á√ÉO\n",
        "# ============================\n",
        "import pandas as pd\n",
        "import fasttext\n",
        "from scipy.spatial.distance import cosine\n",
        "\n",
        "# ============================\n",
        "# FUN√á√ïES AUXILIARES\n",
        "# ============================\n",
        "\n",
        "# Similaridade de cosseno entre dois vetores\n",
        "def similaridade(v1, v2):\n",
        "    return 1 - cosine(v1, v2)\n",
        "\n",
        "# Vetor da palavra (retorna None se n√£o existir no modelo)\n",
        "def vetor_palavra(palavra, modelo):\n",
        "    try:\n",
        "        return modelo.get_word_vector(palavra)\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "# ============================\n",
        "# CARREGAR MODELO FASTTEXT\n",
        "# ============================\n",
        "modelo = fasttext.load_model(\"/content/drive/MyDrive/fastTest/cc.pt.300.bin\")\n",
        "print(\"‚úÖ Modelo carregado com sucesso!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqJoAEUqsQSW",
        "outputId": "c08742ad-98b6-4077-b297-780593a13435"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fasttext\n",
        "import fasttext\n",
        "\n",
        "modelo = fasttext.load_model(\"/content/drive/MyDrive/fastTest/cc.pt.300.bin\")\n",
        "print(\"‚úÖ Modelo carregado com sucesso!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CSpG0PktgSN",
        "outputId": "2996c27b-dcb0-4ba8-ddce-670c25c89733"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fasttext\n",
            "  Downloading fasttext-0.9.3.tar.gz (73 kB)\n",
            "\u001b[?25l     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/73.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m73.4/73.4 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pybind11>=2.2 (from fasttext)\n",
            "  Using cached pybind11-3.0.1-py3-none-any.whl.metadata (10.0 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from fasttext) (75.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from fasttext) (2.0.2)\n",
            "Using cached pybind11-3.0.1-py3-none-any.whl (293 kB)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.3-cp312-cp312-linux_x86_64.whl size=4498211 sha256=4d3097d2735a5d5522e7c7804ff74c5df927cd706cb3f7010bb3445bff297d8f\n",
            "  Stored in directory: /root/.cache/pip/wheels/20/27/95/a7baf1b435f1cbde017cabdf1e9688526d2b0e929255a359c6\n",
            "Successfully built fasttext\n",
            "Installing collected packages: pybind11, fasttext\n",
            "Successfully installed fasttext-0.9.3 pybind11-3.0.1\n",
            "‚úÖ Modelo carregado com sucesso!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "/content/drive/MyDrive/fastTest/cc.pt.300.bin\n"
      ],
      "metadata": {
        "id": "2UtBugaLscZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import fasttext\n",
        "\n",
        "modelo = fasttext.load_model(\"/content/drive/MyDrive/fastTest/cc.pt.300.bin\")\n",
        "print(\"‚úÖ Modelo carregado com sucesso!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQ63yWSisrw1",
        "outputId": "047b8707-e6cb-4476-f8dd-87cbc6eb7d5b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Modelo carregado com sucesso!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eAPKBl8-xO1D",
        "outputId": "bc865d8f-2ce6-4980-a2ad-5f2e97a44345"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 090f0c2c04efb154_733107_1261158_2024-12-15_03-13-25.zip\n",
            " 12A-Webster_240805_121900.pdf\n",
            " 147af5f7-1f31-49ed-944c-ab5b5c66d220.csv\n",
            " 18.full.pdf\n",
            "'1999_Varadarajan&Jayachandran_Marketing strategy An assessment of the state of the field and outlook.docx'\n",
            "'20250707 - parecer banca de projeto de dissertacao - Shaiane.gdoc'\n",
            "'20250707 - parecer banca de projeto de dissertacao - Shaiane.pdf'\n",
            " 25103333-homologa-servidor-24-01-23-pg-61.pdf\n",
            "'67c0d962014d7_Edital n¬∫ 49_2025 - ProrrogacÃßaÃÉo do Edital Processo Seletivo para ContratacÃßaÃÉo de Professor Substituto nas aÃÅreas de AdministracÃßaÃÉo, CieÃÇncias BioloÃÅgicas e EducacÃßaÃÉo FiÃÅsica.pdf'\n",
            " ACADEÃÇMICO\n",
            "'A InflueÃÇncia da MotivacÃßaÃÉo Parental nas DecisoÃÉes de Consumo de Pais MaÃÉes Solo.gdoc'\n",
            "' A InflueÃÇncia da MotivacÃßaÃÉo Parental nas DecisoÃÉes de Consumo de Pais MaÃÉes Solo (VersaÃÉo Desvinculada).gdoc'\n",
            "'AK SEMESTRAL NOVEMBRO 2019 NOITE.docx'\n",
            "'analise critica marketing.odt'\n",
            "'AnaÃÅlise de HipoÃÅteses de Pesquisa AcadeÃÇmica.gdoc'\n",
            " articles.csv\n",
            " articles.xlsx\n",
            "'Artigos sugeridos para replicacÃßaÃÉo '\n",
            "'Atendimento telefone.pdf'\n",
            "'Avaliando o ChatGPT como substituto de clientes na a medicÃßaÃÉo do Customer perceived value (CPV) de um produto..docx'\n",
            "'Avaliando o ChatGPT como substituto de clientes na a medicÃßaÃÉo do Customer perceived value (CPV) de um produto..gdoc'\n",
            "'BACK NOTE AUXI'\n",
            "'Bases - RSL.gsheet'\n",
            "'Colab Notebooks'\n",
            "'comprovante de matricula.pdf'\n",
            "'Conversa do WhatsApp com +55 51 8599-1141.gdoc'\n",
            "'CoÃÅpia de A InflueÃÇncia da MotivacÃßaÃÉo Parental nas DecisoÃÉes de Consumo de Pais MaÃÉes Solo - 2 de dezembro, 14:38.gdoc'\n",
            "'CoÃÅpia de A InflueÃÇncia da MotivacÃßaÃÉo Parental nas DecisoÃÉes de Consumo de Pais MaÃÉes Solo.gdoc'\n",
            "'CoÃÅpia de A InflueÃÇncia da MotivacÃßaÃÉo Parental no Foco Temporal de Pais MaÃÉes Solo .docx'\n",
            "'CoÃÅpia de articles.xlsx'\n",
            "'CoÃÅpia de curriculo Shaiane.docx.gdoc'\n",
            "'CoÃÅpia de Ensaio para Paper - Adm de MKT.gdoc'\n",
            "'CoÃÅpia de SegurancÃßa - Artigo Brei.gdoc'\n",
            "'Crescent Pure Case (1).pdf'\n",
            "'Cronograma 2024_2_PPG ADM - ConveÃÇnio.gdoc'\n",
            "'Cronograma 2024_2_PPG ADM - ConveÃÇnio.pdf'\n",
            "'curriculo Shaiane.doc.gdoc'\n",
            "'curriculo Shaiane.docx.gdoc'\n",
            "'Desafios da orientacÃßaÃÉo para o cliente - O lado obscuro da cultura organizacional e os comportamentos sabotadores - Uma perspectiva teoÃÅrica e gerencial (1).pdf'\n",
            "'Desafios da orientacÃßaÃÉo para o cliente - O lado obscuro da cultura organizacional e os comportamentos sabotadores - Uma perspectiva teoÃÅrica e gerencial.pdf'\n",
            "'DescricÃßaÃÉo cargos (5).xlsx'\n",
            "'DescricÃßaÃÉo cargos.xlsx.gsheet'\n",
            "'Desenho Experimental (QuestionaÃÅrio) (1).pdf'\n",
            "'Desenho Experimental (QuestionaÃÅrio) (2).pdf'\n",
            "'Desenho Experimental (QuestionaÃÅrio) (3).pdf'\n",
            "'Desenho Experimental (QuestionaÃÅrio).gdoc'\n",
            "'Desenho Experimental (QuestionaÃÅrio).pdf'\n",
            " Dicionario\n",
            "'Documento sem tiÃÅtulo (1).gdoc'\n",
            "'Documento sem tiÃÅtulo (2).gdoc'\n",
            "'Documento sem tiÃÅtulo (3).gdoc'\n",
            "'Documento sem tiÃÅtulo (4).gdoc'\n",
            "'Documento sem tiÃÅtulo.gdoc'\n",
            "'Doe 04-11-2022 pag 46-48_888 (1).pdf'\n",
            "'Doe 04-11-2022 pag 46-48_888.pdf'\n",
            "'DOE_2022-11-10 EDITAL SERVIDOR DE ESCOLA_483.pdf'\n",
            "'Encontro 7 - EstrateÃÅgia de Produto (1) (1).pdf'\n",
            "'Encontro 7 - EstrateÃÅgia de Produto (1).pdf'\n",
            "'Ensaios de Aula'\n",
            "'Ensaio TeoÃÅrico - Thais Monteiro - PARTE 1_Cristiane.docx'\n",
            "'Escala HED UT.gsheet'\n",
            "'Escala Tensao de Papeis.gsheet'\n",
            "'Escala Voss.gsheet'\n",
            "'Estudo de Caso capiÃÅtulo 11 - GraÃÅfico de barras 1.gsheet'\n",
            "'Estudo de Caso capiÃÅtulo 11 - GraÃÅfico de colunas 1.gsheet'\n",
            "'ESTUDO DO PERFIL E COMPORTAMENTO DOS CLIENTES QUE BUSCAM IMOÃÅVEIS PARA LOCACÃßAÃÉO EM PORTO ALEGRE.docx'\n",
            "'ESTUDO DO PERFIL E COMPORTAMENTO DOS CLIENTES QUE BUSCAM IMOÃÅVEIS PARA LOCACÃßAÃÉO EM PORTO ALEGRE (Salvo Automaticamente).docx'\n",
            " fastTest\n",
            "'Fichamento RSL (21 a 35).gdoc'\n",
            "'Firestorms - Quando a ReputacÃßaÃÉo da Marca eÃÅ o Alvo nas MiÃÅdias Sociais - VersaÃÉo Final.docx'\n",
            "'FormulaÃÅrio sem tiÃÅtulo (1).gform'\n",
            "'FormulaÃÅrio sem tiÃÅtulo.gform'\n",
            "'FormulaÃÅrio sem tiÃÅtulo (respostas).gsheet'\n",
            "'Gemini, gostaria de um material de correcÃßaÃÉo para....gsheet'\n",
            " HistoÃÅria.docx.gdoc\n",
            "'Ideias de Pesquisa (Painel interativo).pdf'\n",
            "'Imagens Qualtrics'\n",
            "'InteligeÃÇncia Artificial e Arrependimento PoÃÅs-Com_241107_191938.pdf'\n",
            "' InteracÃßoÃÉes Sociais e as PrefereÃÇncias de Consumo.gform'\n",
            "'InteracÃßoÃÉes Sociais e PrefereÃÇncias de Consumo.gform'\n",
            "'InteracÃßoÃÉes Sociais e PrefereÃÇncias de Consumo (respostas).gsheet'\n",
            " intro_ANOVA.xlsx\n",
            "'INTRODUCÃßAÃÉO-AvaliacÃßaÃÉo de desempenho.docx.gdoc'\n",
            "'IntroducÃßaÃÉo Paper - AdminsitracÃßaÃÉo de marketing.gdoc'\n",
            "'IntroducÃßaÃÉo sobre a empresa Natura (1).docx.gdoc'\n",
            "'IntroducÃßaÃÉo sobre a empresa Natura.docx.gdoc'\n",
            "'IP 12.08.gdoc'\n",
            "'IP 12.08.odt'\n",
            "'jagsheth.com-Feeling the Heat Part 2 (1).pdf'\n",
            "'Leituras Cleo'\n",
            "'Lista de convidados.ods'\n",
            "'LOGO VICKENZO - PARA PLACA.pdf'\n",
            "'MAPEAMENTO DO PROCESSO.docx.gdoc'\n",
            "'Material ExerciÃÅcio  Centralidade do Cliente'\n",
            "'Matriz BCG.gdoc'\n",
            "'Meet Recordings'\n",
            " MindMeister\n",
            "'Negativas de Propriedade'\n",
            "' O Peso de ser Dois em Um: A TensaÃÉo de PapeÃÅis e o Consumo HedoÃÇnico de MaÃÉes e Pais Solo.gdoc'\n",
            "'O Peso de ser Dois em Um: A TensaÃÉo de PapeÃÅis e o Consumo HedoÃÇnico de MaÃÉes e Pais Solo.gdoc'\n",
            "'O Peso de ser Dois em Um -  A TensaÃÉo de Papeis e o Consumo Hedonico de Maes e Pais Solo.pdf'\n",
            "' O Peso de ser Dois em Um: A TensaÃÉo de PapeÃÅis e o Consumo HedoÃÇnico de MaÃÉes e Pais Solo (versaÃÉo final).gdoc'\n",
            "'Pesquisa EstaÃÅgio II.gform'\n",
            "'Pesquisa EstaÃÅgio II (respostas).gsheet'\n",
            "' Pesquisa - ExperieÃÇncias de Compra.gform'\n",
            "'Pesquisa - ExperieÃÇncias de Compra.gform'\n",
            "' Pesquisa - ExperieÃÇncias de Compra (respostas).gsheet'\n",
            "'Pesquisa - ExperieÃÇncias de Compra (respostas).gsheet'\n",
            " Pessoal\n",
            "'Plano de AcÃßoÃÉes de Marketing.xls'\n",
            "'Plano_de_Ensino_Comportamento do Consumidor 2024 ALUNO Seminarios (1).doc'\n",
            "'Plano_de_Ensino_Comportamento do Consumidor 2024 ALUNO Seminarios.doc'\n",
            "'Produtos (3).xlsx'\n",
            "'ProjecÃßoÃÉes_relatoÃÅrio (1).xlsx.gsheet'\n",
            " ProjecÃßoÃÉes_relatoÃÅrio.xlsx.gsheet\n",
            "'protocolo chaves 18.12 (1).gdoc'\n",
            "'protocolo chaves 18.12.gdoc'\n",
            "'QuestoÃÉes para Estudo dirigido consumidor.doc'\n",
            "'QuestoÃÉes para Estudo dirigido consumidor.doc.gdoc'\n",
            "'QuestoÃÉes para Estudo dirigido direito do trabalho..doc'\n",
            "'QuestoÃÉes para Estudo dirigido direito do trabalho..doc.gdoc'\n",
            "'Rafael Garcia Ribeiro.gdoc'\n",
            "'Rascunho  - Adm de MKT.gdoc'\n",
            "'Redes - Pacotes turiÃÅsticos.xlsx'\n",
            "'Relacionamentos e as PrefereÃÇncias de Consumo .gform'\n",
            "'Relacionamentos e as PrefereÃÇncias de Consumo  (respostas).gsheet'\n",
            "'Relacionamentos e PrefereÃÇncias de Consumo.gform'\n",
            "'Relacionamentos e PrefereÃÇncias de Consumo (respostas).gsheet'\n",
            "'Roteiro - Aula 14 (Grupos de InflueÃÇncia).docx'\n",
            "'Roteiro - Aula 14 (Grupos de InflueÃÇncia).gdoc'\n",
            "'RSL - RevisaÃÉo SistemaÃÅtica de Literatura.gdoc'\n",
            "' RSL - RevisaÃÉo SistemaÃÅtica de Literatura - VersaÃÉo Final - OSF.gdoc'\n",
            "'RSL - Teoria da TensaÃÉo de PapeÃÅis.gsheet'\n",
            "'Saved from Chrome'\n",
            "'Scopus (20.01.25).csv'\n",
            "'Scopus (20.01.25).gsheet'\n",
            " scopus.csv\n",
            " scopus.gsheet\n",
            "'Scopus - ServicÃßos Concatenados.xlsx'\n",
            "'Scopus - Spillover.xlsx'\n",
            "'Screen_Recording_20240808_184527_Samsung Notes.mp4'\n",
            "'Sem tiÃÅtulo.gdoc'\n",
            "'Simulated_Interacoes_Sociais (1) - CORRIGIDA.xlsx'\n",
            "'Simulated_Relacionamentos - CORRIGIDA.xlsx'\n",
            "'Spillover - Bibliometric.xlsx'\n",
            "'Spillover - Negative.xlsx'\n",
            " TCC.gdoc\n",
            " termo.pdf\n",
            "'Teste Ancoras de Carreira Robert Half (1).xlsx'\n",
            " tga.gdoc\n",
            "'TRABALHO ESCRITO.docx.gdoc'\n",
            " trabalhofinaltga.docx.gdoc\n",
            "'trabalho final tga.gdoc'\n",
            "'TRABALHO TGA EDITADO (1).docx.gdoc'\n",
            "'TRABALHO TGA EDITADO (2).docx.gdoc'\n",
            "'TRABALHO TGA EDITADO (3).docx.gdoc'\n",
            "'TRABALHO TGA EDITADO (4).docx.gdoc'\n",
            "'TRABALHO TGA EDITADO (5).docx.gdoc'\n",
            "'TRABALHO TGA EDITADO.docx.gdoc'\n",
            " U118O6L929309.PDF\n",
            "'Universalidade de Marketing - Aula 10.pdf'\n",
            "'WORD ORDER.docx'\n",
            " Word_order_questions_do_does.docx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/Dicionario\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdAaCw7ExWR_",
        "outputId": "99e2d4aa-e7cb-43a3-a44a-51363663e035"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dicionario_Drivers.xlsx  frequencia_por_driver.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================\n",
        "# IMPORTS E CONFIGURA√á√ÉO\n",
        "# ============================\n",
        "import pandas as pd\n",
        "import fasttext\n",
        "from scipy.spatial.distance import cosine\n",
        "\n",
        "# ============================\n",
        "# FUN√á√ïES AUXILIARES\n",
        "# ============================\n",
        "\n",
        "# Similaridade de cosseno entre dois vetores\n",
        "def similaridade(v1, v2):\n",
        "    return 1 - cosine(v1, v2)\n",
        "\n",
        "# Vetor da palavra (retorna None se n√£o existir no modelo)\n",
        "def vetor_palavra(texto, modelo):\n",
        "    try:\n",
        "        # Faz m√©dia dos vetores das palavras dentro da frase/descri√ß√£o\n",
        "        palavras = str(texto).split()\n",
        "        vetores = [modelo.get_word_vector(p) for p in palavras if p.strip() != \"\"]\n",
        "        return sum(vetores) / len(vetores)\n",
        "    except Exception as e:\n",
        "        return None\n",
        "\n",
        "# ============================\n",
        "# CARREGAR ARQUIVOS\n",
        "# ============================\n",
        "\n",
        "# Ajuste os caminhos de acordo com seu Google Drive\n",
        "dicionario = pd.read_excel(\"/content/drive/MyDrive/Dicionario/Dicionario_Drivers.xlsx\")\n",
        "palavras_nc = pd.read_excel(\"/content/drive/MyDrive/Dicionario/frequencia_por_driver.xlsx\", sheet_name=\"Palavras_Nao_Classificadas\")\n",
        "\n",
        "# ============================\n",
        "# MODELO FASTTEXT (j√° carregado)\n",
        "# ============================\n",
        "# Se j√° carregou antes, pode pular esta parte.\n",
        "# modelo = fasttext.load_model(\"/content/drive/MyDrive/fastTest/cc.pt.300.bin\")\n",
        "\n",
        "# ============================\n",
        "# NORMALIZA√á√ÉO (lowercase e strip)\n",
        "# ============================\n",
        "if 'descricao' in dicionario.columns:\n",
        "    dicionario['descricao_norm'] = dicionario['descricao'].fillna('').str.lower().str.strip()\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Coluna 'descricao' n√£o encontrada no dicion√°rio! Verifique o nome da coluna.\")\n",
        "\n",
        "palavras_nc['Palavra'] = palavras_nc['Palavra'].astype(str).str.lower().str.strip()\n",
        "\n",
        "# ============================\n",
        "# CALCULAR SUGEST√ïES\n",
        "# ============================\n",
        "sugestoes_list = []\n",
        "\n",
        "for idx, row in palavras_nc.iterrows():\n",
        "    palavra = row['Palavra']\n",
        "    vec_pal = vetor_palavra(palavra, modelo)\n",
        "    if vec_pal is None:\n",
        "        continue\n",
        "\n",
        "    sims = []\n",
        "    for jdx, desc_row in dicionario.iterrows():\n",
        "        vec_desc = vetor_palavra(desc_row['descricao_norm'], modelo)\n",
        "        if vec_desc is None:\n",
        "            continue\n",
        "        sims.append((desc_row.get('driver', ''), desc_row.get('subdriver', ''), similaridade(vec_pal, vec_desc)))\n",
        "\n",
        "    # Ordena e pega top 3 sugest√µes\n",
        "    sims_sorted = sorted(sims, key=lambda x: x[2], reverse=True)[:3]\n",
        "    for s in sims_sorted:\n",
        "        sugestoes_list.append({'Palavra': palavra, 'Driver': s[0], 'Subdriver': s[1], 'Similaridade': s[2]})\n",
        "\n",
        "# Criar DataFrame final\n",
        "sugestoes_df = pd.DataFrame(sugestoes_list)\n",
        "sugestoes_df = sugestoes_df.sort_values(['Palavra', 'Similaridade'], ascending=[True, False])\n",
        "\n",
        "# ============================\n",
        "# SALVAR EM EXCEL\n",
        "# ============================\n",
        "output_path = \"/content/drive/MyDrive/Dicionario/sugestoes.xlsx\"\n",
        "with pd.ExcelWriter(output_path) as writer:\n",
        "    palavras_nc.to_excel(writer, sheet_name=\"Palavras_Nao_Classificadas\", index=False)\n",
        "    sugestoes_df.to_excel(writer, sheet_name=\"Sugestoes_De_Encaixe\", index=False)\n",
        "\n",
        "print(f\"üíæ Arquivo salvo com sucesso em: {output_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fi0S4b2SwHS0",
        "outputId": "ac5cecf4-9a73-4513-9f18-c81c87178df3"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/scipy/spatial/distance.py:682: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  dist = 1.0 - uv / math.sqrt(uu * vv)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üíæ Arquivo salvo com sucesso em: /content/drive/MyDrive/Dicionario/sugestoes.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###Classificando as sugest√µes por similaridade####\n",
        "# ============================\n",
        "# Classificar similaridade\n",
        "# ============================\n",
        "def classifica_sim(sim):\n",
        "    if sim >= 0.7:\n",
        "        return \"Alta\"\n",
        "    elif sim >= 0.5:\n",
        "        return \"M√©dia\"\n",
        "    else:\n",
        "        return \"Baixa\"\n",
        "\n",
        "sugestoes_df['Classificacao'] = sugestoes_df['Similaridade'].apply(classifica_sim)\n",
        "\n",
        "# ============================\n",
        "# Salvar resultados no Excel\n",
        "# ============================\n",
        "with pd.ExcelWriter(\"/content/drive/MyDrive/Dicionario/sugestoes_classificadas.xlsx\") as writer:\n",
        "    palavras_nc.to_excel(writer, sheet_name=\"Palavras_Nao_Classificadas\", index=False)\n",
        "    sugestoes_df.to_excel(writer, sheet_name=\"Sugestoes_De_Encaixe\", index=False)\n",
        "\n",
        "print(\"üíæ Arquivo salvo: sugestoes_classificadas.xlsx\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6G-_rRvrzi7F",
        "outputId": "14233e81-9886-4e9d-c1a7-6bd8be64765a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üíæ Arquivo salvo: sugestoes_classificadas.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "####Tentando melhorar as sugest√µes de classifica√ß√£o de palavras pelo FastTest usando uma vers√£o mais robusta para o FastTest:\n",
        "\n",
        "import pandas as pd\n",
        "from scipy.spatial.distance import cosine\n",
        "\n",
        "# ============================\n",
        "# FUN√á√ïES AUXILIARES\n",
        "# ============================\n",
        "\n",
        "def similaridade(v1, v2):\n",
        "    return 1 - cosine(v1, v2)\n",
        "\n",
        "def vetor_palavra(palavra, modelo):\n",
        "    try:\n",
        "        return modelo.get_word_vector(palavra)\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "def ajustar_valencia(sim, palavra_val, desc_val):\n",
        "    \"\"\"\n",
        "    Ajusta a similaridade de acordo com a val√™ncia:\n",
        "    - Mesma val√™ncia -> refor√ßa (multiplica 1.2)\n",
        "    - Val√™ncia oposta -> penaliza (multiplica 0.8)\n",
        "    - Sem val√™ncia -> mant√©m\n",
        "    \"\"\"\n",
        "    if pd.isna(palavra_val) or pd.isna(desc_val):\n",
        "        return sim\n",
        "    if palavra_val == desc_val:\n",
        "        return sim * 1.2\n",
        "    elif palavra_val != desc_val:\n",
        "        return sim * 0.8\n",
        "    else:\n",
        "        return sim\n",
        "\n",
        "# ============================\n",
        "# CARREGAR PLANILHAS\n",
        "# ============================\n",
        "\n",
        "palavras_nc = pd.read_excel(\"/content/drive/MyDrive/Dicionario/sugestoes_classificadas.xlsx\",\n",
        "                            sheet_name=\"Palavras_Nao_Classificadas\")\n",
        "\n",
        "dicionario = pd.read_excel(\"/content/drive/MyDrive/Dicionario/Dicionario_Drivers.xlsx\")\n",
        "\n",
        "# Adiciona coluna de val√™ncia\n",
        "dicionario['valencia'] = dicionario.apply(\n",
        "    lambda row: 'positivo' if pd.notna(row['dicionarioP']) else ('negativo' if pd.notna(row['dicionarioN']) else None),\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "# Normaliza√ß√£o\n",
        "dicionario['descricao_norm'] = dicionario['descricao'].fillna('').str.lower().str.strip()\n",
        "palavras_nc['Palavra'] = palavras_nc['Palavra'].astype(str).str.lower().str.strip()\n",
        "\n",
        "# ============================\n",
        "# Dicion√°rios de val√™ncia para palavras n√£o classificadas\n",
        "# ============================\n",
        "\n",
        "# Cria um dicion√°rio r√°pido para palavras do dicion√°rio\n",
        "valencia_dict = {}\n",
        "for idx, row in dicionario.iterrows():\n",
        "    for col in ['dicionarioP', 'dicionarioN']:\n",
        "        palavra = row[col]\n",
        "        if pd.notna(palavra):\n",
        "            palavra_norm = palavra.lower().strip()\n",
        "            valencia_dict[palavra_norm] = 'positivo' if col=='dicionarioP' else 'negativo'\n",
        "\n",
        "# ============================\n",
        "# GERA√á√ÉO DE SUGEST√ïES AVAN√áADAS\n",
        "# ============================\n",
        "\n",
        "def gerar_sugestoes_avancadas(palavras_df, dicionario, top_n=3, threshold_sim=0.3):\n",
        "    sugestoes_list = []\n",
        "\n",
        "    for idx, row in palavras_df.iterrows():\n",
        "        palavra = row['Palavra']\n",
        "        freq = row.get('Frequencia', 1)  # se houver coluna de frequ√™ncia\n",
        "        palavra_val = valencia_dict.get(palavra, None)\n",
        "\n",
        "        vec_pal = vetor_palavra(palavra, modelo)\n",
        "        if vec_pal is None:\n",
        "            continue\n",
        "\n",
        "        sims = []\n",
        "        for jdx, desc_row in dicionario.iterrows():\n",
        "            vec_desc = vetor_palavra(desc_row['descricao_norm'], modelo)\n",
        "            if vec_desc is None:\n",
        "                continue\n",
        "            sim = similaridade(vec_pal, vec_desc)\n",
        "            sim = ajustar_valencia(sim, palavra_val, desc_row['valencia'])\n",
        "            if sim >= threshold_sim:\n",
        "                sims.append((desc_row['driver'], desc_row['subdriver'], desc_row['valencia'], sim))\n",
        "\n",
        "        sims_sorted = sorted(sims, key=lambda x: (x[3], freq), reverse=True)[:top_n]\n",
        "\n",
        "        for s in sims_sorted:\n",
        "            sugestoes_list.append({\n",
        "                'Palavra': palavra,\n",
        "                'Frequencia': freq,\n",
        "                'Driver': s[0],\n",
        "                'Subdriver': s[1],\n",
        "                'Valencia': s[2],\n",
        "                'Similaridade': s[3]\n",
        "            })\n",
        "\n",
        "    return pd.DataFrame(sugestoes_list)\n",
        "\n",
        "# ============================\n",
        "# RODAR SUGEST√ïES\n",
        "# ============================\n",
        "\n",
        "sugestoes_df = gerar_sugestoes_avancadas(palavras_nc, dicionario, top_n=3, threshold_sim=0.3)\n",
        "sugestoes_df = sugestoes_df.sort_values(['Palavra', 'Similaridade'], ascending=[True, False])\n",
        "\n",
        "# ============================\n",
        "# CLASSIFICAR POR SIMILARIDADE\n",
        "# ============================\n",
        "\n",
        "def classifica_sim(sim):\n",
        "    if sim >= 0.7:\n",
        "        return \"Alta\"\n",
        "    elif sim >= 0.5:\n",
        "        return \"M√©dia\"\n",
        "    else:\n",
        "        return \"Baixa\"\n",
        "\n",
        "sugestoes_df['Classificacao'] = sugestoes_df['Similaridade'].apply(classifica_sim)\n",
        "\n",
        "# ============================\n",
        "# SALVAR RESULTADOS COM CLASSIFICA√á√ÉO\n",
        "# ============================\n",
        "\n",
        "with pd.ExcelWriter(\"/content/drive/MyDrive/Dicionario/sugestoes_classificadas.xlsx\", mode='a', if_sheet_exists='replace') as writer:\n",
        "    palavras_nc.to_excel(writer, sheet_name=\"Palavras_Nao_Classificadas\", index=False)\n",
        "    sugestoes_df.to_excel(writer, sheet_name=\"Sugestoes_FastText_Avancadas\", index=False)\n",
        "\n",
        "print(\"üíæ Arquivo atualizado com aba: Sugestoes_FastText_Avancadas e Classificacao de Similaridade\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RIGOCGawAJnA",
        "outputId": "bc1049c0-7801-43bf-a92b-1bec6a384f5b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/scipy/spatial/distance.py:682: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  dist = 1.0 - uv / math.sqrt(uu * vv)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üíæ Arquivo atualizado com aba: Sugestoes_FastText_Avancadas e Classificacao de Similaridade\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#### Algumas palavras foram classificadas como positivas mas, claramente s√£o negativas ex: denuncia. Tentando um dicion√°rio de ant√¥nimos para ver se melhora####\n",
        "\n",
        "#### Sugest√µes FastText aprimoradas com detec√ß√£o autom√°tica de val√™ncia e consolida√ß√£o ####\n",
        "\n",
        "import pandas as pd\n",
        "from scipy.spatial.distance import cosine\n",
        "import math\n",
        "\n",
        "# ============================\n",
        "# FUN√á√ïES AUXILIARES\n",
        "# ============================\n",
        "\n",
        "def similaridade(v1, v2):\n",
        "    return 1 - cosine(v1, v2)\n",
        "\n",
        "def vetor_palavra(palavra, modelo):\n",
        "    try:\n",
        "        return modelo.get_word_vector(palavra)\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "def detectar_valencia(palavra_vec, pos_vecs, neg_vecs):\n",
        "    \"\"\"\n",
        "    Detecta a val√™ncia da palavra com base na similaridade m√©dia com\n",
        "    palavras positivas e negativas do dicion√°rio.\n",
        "    Retorna 'positivo', 'negativo' ou None.\n",
        "    \"\"\"\n",
        "    if palavra_vec is None:\n",
        "        return None\n",
        "\n",
        "    sim_pos = [similaridade(palavra_vec, v) for v in pos_vecs if v is not None]\n",
        "    sim_neg = [similaridade(palavra_vec, v) for v in neg_vecs if v is not None]\n",
        "\n",
        "    mean_pos = sum(sim_pos)/len(sim_pos) if sim_pos else 0\n",
        "    mean_neg = sum(sim_neg)/len(sim_neg) if sim_neg else 0\n",
        "\n",
        "    if mean_pos > mean_neg:\n",
        "        return 'positivo'\n",
        "    elif mean_neg > mean_pos:\n",
        "        return 'negativo'\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "# ============================\n",
        "# CARREGAR PLANILHAS\n",
        "# ============================\n",
        "\n",
        "palavras_nc = pd.read_excel(\"/content/drive/MyDrive/Dicionario/sugestoes_classificadas.xlsx\",\n",
        "                            sheet_name=\"Palavras_Nao_Classificadas\")\n",
        "\n",
        "dicionario = pd.read_excel(\"/content/drive/MyDrive/Dicionario/Dicionario_Drivers.xlsx\")\n",
        "\n",
        "# Adiciona coluna de val√™ncia\n",
        "dicionario['valencia'] = dicionario.apply(\n",
        "    lambda row: 'positivo' if pd.notna(row['dicionarioP']) else ('negativo' if pd.notna(row['dicionarioN']) else None),\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "# Normaliza√ß√£o\n",
        "dicionario['descricao_norm'] = dicionario['descricao'].fillna('').str.lower().str.strip()\n",
        "palavras_nc['Palavra'] = palavras_nc['Palavra'].astype(str).str.lower().str.strip()\n",
        "\n",
        "# ============================\n",
        "# Criar listas de vetores positivos e negativos do dicion√°rio\n",
        "# ============================\n",
        "\n",
        "palavras_positivas = [p.lower().strip() for p in dicionario['dicionarioP'].dropna()]\n",
        "palavras_negativas = [p.lower().strip() for p in dicionario['dicionarioN'].dropna()]\n",
        "\n",
        "pos_vecs = [vetor_palavra(p, modelo) for p in palavras_positivas]\n",
        "neg_vecs = [vetor_palavra(p, modelo) for p in palavras_negativas]\n",
        "\n",
        "# ============================\n",
        "# GERA√á√ÉO DE SUGEST√ïES APRIMORADAS\n",
        "# ============================\n",
        "\n",
        "def gerar_sugestoes_valencia_automatica(palavras_df, dicionario, top_n=3, threshold_sim=0.3):\n",
        "    sugestoes_list = []\n",
        "\n",
        "    for idx, row in palavras_df.iterrows():\n",
        "        palavra = row['Palavra']\n",
        "        freq = row.get('Frequencia', 1)\n",
        "        vec_pal = vetor_palavra(palavra, modelo)\n",
        "        if vec_pal is None:\n",
        "            continue\n",
        "\n",
        "        palavra_val = detectar_valencia(vec_pal, pos_vecs, neg_vecs)\n",
        "\n",
        "        sims = []\n",
        "        for jdx, desc_row in dicionario.iterrows():\n",
        "            vec_desc = vetor_palavra(desc_row['descricao_norm'], modelo)\n",
        "            if vec_desc is None:\n",
        "                continue\n",
        "\n",
        "            sim = similaridade(vec_pal, vec_desc)\n",
        "\n",
        "            # Ajusta similaridade por val√™ncia\n",
        "            if palavra_val == desc_row['valencia']:\n",
        "                sim *= 1.2\n",
        "            elif palavra_val and desc_row['valencia'] and palavra_val != desc_row['valencia']:\n",
        "                sim *= 0.8\n",
        "\n",
        "            if sim >= threshold_sim:\n",
        "                sim_freq = sim * math.log(1 + freq)\n",
        "                sims.append((desc_row['driver'], desc_row['subdriver'], desc_row['valencia'], sim_freq))\n",
        "\n",
        "        sims_sorted = sorted(sims, key=lambda x: x[3], reverse=True)[:top_n]\n",
        "\n",
        "        for s in sims_sorted:\n",
        "            sugestoes_list.append({\n",
        "                'Palavra': palavra,\n",
        "                'Frequencia': freq,\n",
        "                'Driver': s[0],\n",
        "                'Subdriver': s[1],\n",
        "                'Valencia': s[2],\n",
        "                'Similaridade': s[3]\n",
        "            })\n",
        "\n",
        "    return pd.DataFrame(sugestoes_list)\n",
        "\n",
        "# ============================\n",
        "# RODAR SUGEST√ïES\n",
        "# ============================\n",
        "\n",
        "sugestoes_df = gerar_sugestoes_valencia_automatica(palavras_nc, dicionario, top_n=3, threshold_sim=0.3)\n",
        "sugestoes_df = sugestoes_df.sort_values(['Palavra', 'Similaridade'], ascending=[True, False])\n",
        "\n",
        "# ============================\n",
        "# CONSOLIDAR PALAVRAS PARA TER APENAS UMA LINHA POR PALAVRA\n",
        "# ============================\n",
        "\n",
        "sugestoes_consolidadas = sugestoes_df.groupby('Palavra').agg({\n",
        "    'Frequencia': 'first',\n",
        "    'Driver': lambda x: ', '.join(x.unique()),\n",
        "    'Subdriver': lambda x: ', '.join(x.unique()),\n",
        "    'Valencia': lambda x: ', '.join(x.unique()),\n",
        "    'Similaridade': 'max'\n",
        "}).reset_index()\n",
        "\n",
        "# Classifica√ß√£o por similaridade\n",
        "def classifica_sim(sim):\n",
        "    if sim >= 0.7:\n",
        "        return \"Alta\"\n",
        "    elif sim >= 0.5:\n",
        "        return \"M√©dia\"\n",
        "    else:\n",
        "        return \"Baixa\"\n",
        "\n",
        "sugestoes_consolidadas['Classificacao'] = sugestoes_consolidadas['Similaridade'].apply(classifica_sim)\n",
        "\n",
        "# ============================\n",
        "# SALVAR RESULTADOS NO EXCEL\n",
        "# ============================\n",
        "\n",
        "with pd.ExcelWriter(\"/content/drive/MyDrive/Dicionario/sugestoes_classificadas.xlsx\", mode='a', if_sheet_exists='replace') as writer:\n",
        "    palavras_nc.to_excel(writer, sheet_name=\"Palavras_Nao_Classificadas\", index=False)\n",
        "    sugestoes_consolidadas.to_excel(writer, sheet_name=\"Sugestoes_FastText_Avancadas\", index=False)\n",
        "\n",
        "print(\"üíæ Arquivo atualizado com aba: Sugestoes_FastText_Avancadas e Classificacao de Similaridade\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jllTeO9TAPQ8",
        "outputId": "af6502a2-3b3d-4729-eff3-2caefd7d1721"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/scipy/spatial/distance.py:682: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  dist = 1.0 - uv / math.sqrt(uu * vv)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üíæ Arquivo atualizado com aba: Sugestoes_FastText_Avancadas e Classificacao de Similaridade\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H-EdJ0xIDuJ6"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN/NcTgJ93WfPzhE2RNMbj2",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}